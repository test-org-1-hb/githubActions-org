name: K8sGPT (Ollama) Analysis Pipeline

on:
  push:
    branches: [ "main" ]
  workflow_dispatch:

jobs:
  # ============================================
  # JOB 1: Pre-Deployment Manifest Scan
  # ============================================
  scan-manifests:
    name: "Scan K8s Manifests (Ollama)"
    runs-on: ubuntu-latest
    steps:
      - name: "Checkout code"
        uses: actions/checkout@v4
      
      - name: "Install and Run Ollama"
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          ollama serve &
          sleep 15
        
      - name: "Pull Ollama Model"
        run: |
          ollama pull llama2
      
      - name: "Install K8sGPT"
        run: |
          curl -LO https://github.com/k8sgpt-ai/k8sgpt/releases/download/v0.4.25/k8sgpt_amd64.deb
          sudo dpkg -i k8sgpt_amd64.deb
      
      - name: "Configure K8sGPT for Ollama"
        run: |
          k8sgpt auth add --backend ollama --model llama2 --baseurl http://localhost:11434

      - name: "Analyze local manifest files"
        run: |
          echo "Scanning manifest files in the ./k8s directory with Ollama..."
          k8sgpt analyze --local=./k8s --explain --fail-on-error

  # ==================================================
  # JOB 2: Deploy and Verify Post-Deployment Health
  # ==================================================
  deploy-and-verify:
    name: "Deploy and Verify Health (Ollama)"
    runs-on: ubuntu-latest
    needs: scan-manifests
    steps:
      - name: "Checkout code"
        uses: actions/checkout@v4

      - name: "Install and Run Ollama"
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          ollama serve &
          sleep 15
        
      - name: "Pull Ollama Model"
        run: |
          ollama pull llama2
      
      - name: "Install K8sGPT"
        run: |
          curl -LO https://github.com/k8sgpt-ai/k8sgpt/releases/download/v0.4.25/k8sgpt_amd64.deb
          sudo dpkg -i k8sgpt_amd64.deb
      
      - name: "Configure K8sGPT for Ollama"
        run: |
          k8sgpt auth add --backend ollama --model llama2 --baseurl http://localhost:11434
      
      - name: "Setup Kubeconfig"
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBE_CONFIG }}" | base64 --decode > $HOME/.kube/config
          chmod 600 $HOME/.kube/config
        
      - name: "Deploy to Cluster"
        run: |
          kubectl apply -f ./k8s

      - name: "Wait for deployment to stabilize"
        run: |
          echo "Waiting 30 seconds for resources to initialize..."
          sleep 30

      - name: "Analyze live cluster deployment"
        run: |
          echo "Scanning the 'default' namespace with Ollama..."
          k8sgpt analyze --namespace=default --explain --fail-on-error
